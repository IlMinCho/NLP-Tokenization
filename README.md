# NLP-Tokenization

– Tokenization (spaces or fancy)
– Stopping (not or with a list)
– Stemming (not or Porter steps 1a-1c)
– Input (gzip!): train, S&S
– Output: Prefix / Tokens, heaps, stats

-----------------------------------------
